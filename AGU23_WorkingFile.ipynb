{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMeqsmuclXB+zx8CvThOGC4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ueofficer/AGU23_Workshop/blob/main/AGU23_WorkingFile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **This notebook is developed for AGU 2023**\n",
        "\n",
        "## Example 1 - Conductivity Temperature Depth\n",
        "\n",
        "Data Product - Time Series Scalar Data (define *CTD, data columns,*)\n",
        "\n",
        "Location - Folger Passage > Folger Deep\n",
        "\n",
        "Period - 06-Jul-2013 to 07-Jul-2023"
      ],
      "metadata": {
        "id": "xoyrqeZARuIC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Request Data Product\n",
        "\n",
        "Jan 15, 9:05"
      ],
      "metadata": {
        "id": "ciyip-QlQBYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "mNveJfe2iy0n"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://data.oceannetworks.ca/api/dataProductDelivery'\n",
        "parameters = {'method':'request',\n",
        "            'token':'7cc08ace-86d7-4136-9dcd-dd73017d35ae',\n",
        "            'locationCode':'FGPD',\n",
        "            'deviceCategoryCode':'CTD',\n",
        "            'dataProductCode':'TSSD',\n",
        "            'dateFrom':'2022-01-15T00:00:00.000Z',\n",
        "            'dateTo':'2022-01-18T00:00:00.000Z',\n",
        "            'extension':'csv',\n",
        "            'dpo_qualityControl':'0',\n",
        "            'dpo_dataGaps':'1',\n",
        "            'dpo_resample':'none'} # replace YOUR_TOKEN_HERE with your personal token obtained from the 'Web Services API' tab at https://data.oceannetworks.ca/Profile when logged in.\n",
        "\n",
        "response = requests.get(url,params=parameters)\n",
        "\n"
      ],
      "metadata": {
        "id": "Eb-SAcq3jZof"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (response.ok):\n",
        "    requestInfo = json.loads(str(response.content,'utf-8')) # convert the json response to an object\n",
        "\n",
        "    print('Request Id: {}'.format(requestInfo['dpRequestId']))      # Print the Request Id\n",
        "\n",
        "    if ('numFiles' in requestInfo.keys()):\n",
        "        print('File Count: {}'.format(requestInfo['numFiles']))     # Print the Estimated File Size\n",
        "\n",
        "    if ('fileSize' in requestInfo.keys()):\n",
        "        print('File Size: {}'.format(requestInfo['fileSize']))      # Print the Estimated File Size\n",
        "\n",
        "    if 'downloadTimes' in requestInfo.keys():\n",
        "        print('Estimated download time:')\n",
        "        for e in sorted(requestInfo['downloadTimes'].items(),key=lambda t: t[1]):\n",
        "            print('  {} - {} sec'.format(e[0],'{:0.2f}'.format(e[1])))\n",
        "\n",
        "\n",
        "    if 'estimatedFileSize' in requestInfo.keys():\n",
        "        print('Estimated File Size: {}'.format(requestInfo['estimatedFileSize']))\n",
        "\n",
        "    if 'estimatedProcessingTime' in requestInfo.keys():\n",
        "        print('Estimated Processing Time: {}'.format(requestInfo['estimatedProcessingTime']))\n",
        "\n",
        "else:\n",
        "    if(response.status_code == 400):\n",
        "        error = json.loads(str(response.content,'utf-8'))\n",
        "        print(error) # json response contains a list of errors, with an errorMessage and parameter\n",
        "    else:\n",
        "        print ('Error {} - {}'.format(response.status_code,response.reason))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dcr6b_269Tjh",
        "outputId": "56030083-1c54-4fe3-d3e7-e94c30126fa9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Request Id: 15089503\n",
            "Estimated File Size: No estimated file size available.\n",
            "Estimated Processing Time: No estimated processing time available.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "url = 'https://data.oceannetworks.ca/api/dataProductDelivery'\n",
        "parameters = {'method':'run',\n",
        "            'token':'7cc08ace-86d7-4136-9dcd-dd73017d35ae',              # replace YOUR_TOKEN_HERE with your personal token obtained from the 'Web Services API' tab at https://data.oceannetworks.ca/Profile when logged in.\n",
        "           'dpRequestId':15089503}     # replace YOUR_REQUEST_ID_HERE with a requestId number returned from the request method\n",
        "response = requests.get(url,params=parameters)\n",
        "\n",
        "if (response.ok):\n",
        "    r = json.loads(str(response.content,'utf-8')) # convert the json response to an object\n",
        "\n",
        "    for runId in [run['dpRunId'] for run in r]:\n",
        "        print('Run Id: {}'.format(runId))       # Print each of the Run Ids\n",
        "\n",
        "else:\n",
        "    if(response.status_code == 400):\n",
        "        error = json.loads(str(response.content,'utf-8'))\n",
        "        print(error) # json response contains a list of errors, with an errorMessage and parameter\n",
        "    else:\n",
        "        print ('Error {} - {}'.format(response.status_code,response.reason))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hsj0nP9sDCYW",
        "outputId": "2327645c-13b9-4fc2-e6e9-2e3cdc63fa9d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run Id: 33587069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import os\n",
        "from contextlib import closing\n",
        "import errno\n",
        "\n",
        "url = 'https://data.oceannetworks.ca/api/dataProductDelivery'\n",
        "parameters = {'method':'download',\n",
        "            'token':'7cc08ace-86d7-4136-9dcd-dd73017d35ae',   # replace YOUR_TOKEN_HERE with your personal token obtained from the 'Web Services API' tab at https://data.oceannetworks.ca/Profile when logged in..\n",
        "            'dpRunId':33587069,       # replace YOUR_RUN_ID with the dpRunId returned from the 'run' method.\n",
        "            'index':1}                   # for run requests that contain more than one file, change the index number to the index of the file you would like to download.\n",
        "                                           # If the index number does not exist an HTTP 410 and a message will be returned.\n",
        "\n",
        "\n",
        "outPath='C:/Users/tricyaquino/Desktop/TRICY/UE-Officer/AD-HOC/AGU Workshop'                        # replace with the file location you would like the file to be downloaded to.\n",
        "\n",
        "with closing(requests.get(url,params=parameters,stream=True)) as streamResponse:\n",
        "    if streamResponse.status_code == 200: #OK\n",
        "        if 'Content-Disposition' in streamResponse.headers.keys():\n",
        "            content = streamResponse.headers['Content-Disposition']\n",
        "            filename = content.split('filename=')[1]\n",
        "        else:\n",
        "            print('Error: Invalid Header')\n",
        "            streamResponse.close()\n",
        "            sys.exit(-1)\n",
        "\n",
        "        filePath = '{}/{}'.format(outPath,filename)\n",
        "        try:\n",
        "            if (not os.path.isfile(filePath)):\n",
        "                #Create the directory structure if it doesn't already exist\n",
        "                try:\n",
        "                    os.makedirs(outPath)\n",
        "                except OSError as exc:\n",
        "                    if exc.errno == errno.EEXIST and os.path.isdir(outPath):\n",
        "                        pass\n",
        "                    else:\n",
        "                        raise\n",
        "                print (\"Downloading '{}'\".format(filename))\n",
        "\n",
        "                with open(filePath,'wb') as handle:\n",
        "                    try:\n",
        "                        for block in streamResponse.iter_content(1024):\n",
        "                            handle.write(block)\n",
        "                    except KeyboardInterrupt:\n",
        "                        print('Process interupted: Deleting {}'.format(filePath))\n",
        "                        handle.close()\n",
        "                        streamResponse.close()\n",
        "                        os.remove(filePath)\n",
        "                        sys.exit(-1)\n",
        "            else:\n",
        "                print (\"  Skipping '{}': File Already Exists\".format(filename))\n",
        "        except:\n",
        "            msg = 'Error streaming response.'\n",
        "            print(msg)\n",
        "    else:\n",
        "        if(streamResponse.status_code in [202,204,400,404,410]):\n",
        "            payload = json.loads(str(streamResponse.content,'utf-8'))\n",
        "            if len(payload) >= 1:\n",
        "                msg = payload['message']\n",
        "                print('HTTP {} - {}: {}'.format(streamResponse.status_code,streamResponse.reason,msg))\n",
        "        else:\n",
        "            print ('Error {} - {}'.format(streamResponse.status_code,streamResponse.reason))\n",
        "\n",
        "streamResponse.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUDGy_3mDQ3L",
        "outputId": "750fb8df-1436-4abc-ee7d-e9b31425f840"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 'FolgerPassage_FolgerDeep_ConductivityTemperatureDepth_20220115T000000Z_20220117T235959Z-NaN.csv'\n"
          ]
        }
      ]
    }
  ]
}